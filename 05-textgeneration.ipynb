{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47777d143613441d9eb3eb695037927f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19ae9d914f54059b7adbc44d328c051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d47b3afe424cfbad08a2381de9f2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f564d70e6c944a15beec35ff767300ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8aae9074b54e54b10127aa26204e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"gpt2-xl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>choice_0</th>\n",
       "      <th>choice_1</th>\n",
       "      <th>choice_2</th>\n",
       "      <th>choice_3</th>\n",
       "      <th>choice_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>(0.15)</td>\n",
       "      <td>ills (0.15)</td>\n",
       "      <td>________ (0.07)</td>\n",
       "      <td>icky (0.05)</td>\n",
       "      <td>_____ (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>most (0.07)</td>\n",
       "      <td>ultimate (0.05)</td>\n",
       "      <td>original (0.02)</td>\n",
       "      <td>\" (0.02)</td>\n",
       "      <td>main (0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers are the  most</td>\n",
       "      <td>popular (0.17)</td>\n",
       "      <td>common (0.05)</td>\n",
       "      <td>powerful (0.05)</td>\n",
       "      <td>famous (0.04)</td>\n",
       "      <td>successful (0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are the  most popular</td>\n",
       "      <td>toy (0.10)</td>\n",
       "      <td>toys (0.07)</td>\n",
       "      <td>Transformers (0.06)</td>\n",
       "      <td>of (0.06)</td>\n",
       "      <td>and (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformers are the  most popular toy</td>\n",
       "      <td>line (0.50)</td>\n",
       "      <td>in (0.10)</td>\n",
       "      <td>of (0.08)</td>\n",
       "      <td>lines (0.05)</td>\n",
       "      <td>line (0.04)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers are the  most popular toy line</td>\n",
       "      <td>in (0.37)</td>\n",
       "      <td>of (0.14)</td>\n",
       "      <td>, (0.06)</td>\n",
       "      <td>on (0.04)</td>\n",
       "      <td>. (0.03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers are the  most popular toy line in</td>\n",
       "      <td>the (0.71)</td>\n",
       "      <td>history (0.08)</td>\n",
       "      <td>America (0.04)</td>\n",
       "      <td>Japan (0.02)</td>\n",
       "      <td>all (0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformers are the  most popular toy line in...</td>\n",
       "      <td>world (0.68)</td>\n",
       "      <td>US (0.05)</td>\n",
       "      <td>history (0.03)</td>\n",
       "      <td>universe (0.03)</td>\n",
       "      <td>United (0.03)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input         choice_0   \n",
       "0                              Transformers are the            (0.15)  \\\n",
       "1                             Transformers are the        most (0.07)   \n",
       "2                         Transformers are the  most   popular (0.17)   \n",
       "3                 Transformers are the  most popular       toy (0.10)   \n",
       "4             Transformers are the  most popular toy      line (0.50)   \n",
       "5        Transformers are the  most popular toy line        in (0.37)   \n",
       "6     Transformers are the  most popular toy line in       the (0.71)   \n",
       "7  Transformers are the  most popular toy line in...     world (0.68)   \n",
       "\n",
       "          choice_1              choice_2          choice_3            choice_4  \n",
       "0      ills (0.15)       ________ (0.07)       icky (0.05)        _____ (0.05)  \n",
       "1  ultimate (0.05)       original (0.02)          \" (0.02)         main (0.02)  \n",
       "2    common (0.05)       powerful (0.05)     famous (0.04)   successful (0.03)  \n",
       "3      toys (0.07)   Transformers (0.06)         of (0.06)          and (0.05)  \n",
       "4        in (0.10)             of (0.08)      lines (0.05)         line (0.04)  \n",
       "5        of (0.14)              , (0.06)         on (0.04)            . (0.03)  \n",
       "6   history (0.08)        America (0.04)      Japan (0.02)          all (0.01)  \n",
       "7        US (0.05)        history (0.03)   universe (0.03)       United (0.03)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text = \"Transformers are the \"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "iterations = []\n",
    "num_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(num_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids)[0]\n",
    "        # Select logits of the first batch and the last token\n",
    "        logits = output[0, -1, :]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(probs, descending=True)\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = probs[token_id].cpu().numpy()\n",
    "            token_choice = tokenizer.decode(token_id) + f\" ({token_prob:.2f})\"\n",
    "            iteration[f\"choice_{choice_idx}\"] = token_choice\n",
    "        input_ids = torch.cat((input_ids, sorted_ids[None, 0, None]), dim=1)\n",
    "        iterations.append(iteration)\n",
    "pd.DataFrame(iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
